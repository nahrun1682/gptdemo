import streamlit as st
import requests
import base64
import os
from dotenv import load_dotenv

load_dotenv(os.path.join(os.path.dirname(__file__), '..', '.env'))
# ç’°å¢ƒå¤‰æ•°ã‹ã‚‰OpenAI API Keyã‚’å–å¾—
openai_api_key = os.environ["OPENAI_API_KEY"]

# Function to encode the image to base64
def encode_image(uploaded_image):
    return base64.b64encode(uploaded_image.getvalue()).decode('utf-8')

st.title('ğŸ–¼ï¸ OpenAI Image Response')


# Streamlitã‚’ä½¿ã£ã¦ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹
uploaded_file = st.file_uploader("ç”»åƒã‚’é¸æŠã—ã¦ãã ã•ã„(jpg,png,jpegã®ã¿å¯¾å¿œ)", type=['jpg', 'png', 'jpeg'])
user_input = st.text_input("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆä¾‹ï¼šã“ã®ç”»åƒã«ã¯ä½•ãŒæ˜ ã£ã¦ã„ã¾ã™ã‹ï¼Ÿï¼‰")

if st.button('GPT4-visionã«èã'):
    if uploaded_file is not None:
        # Display the uploaded image
        st.image(uploaded_file, caption='Uploaded Image', use_column_width=True)

        # Encode the image to base64
        base64_image = encode_image(uploaded_file)

        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {openai_api_key}"
        }

        payload = {
            "model": "gpt-4-vision-preview",
            "messages": [
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "text",
                            "text": user_input+"â– å¿…ãšæ—¥æœ¬èªã§å›ç­”ã—ã¦ãã ã•ã„"
                        },
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/jpeg;base64,{base64_image}"
                            }
                        }
                    ]
                }
            ],
            "max_tokens": 1000
        }

        # APIã¸ã®POSTãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’è¡Œã„ã€ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’å¾—ã‚‹
        response = requests.post("https://api.openai.com/v1/chat/completions", headers=headers, json=payload)
        
        # ãƒ‡ãƒãƒƒã‚°ã®ãŸã‚ã«å¿œç­”ã‚’ãƒ—ãƒªãƒ³ãƒˆ
        print(response.json())
        
        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ç¢ºèªã—ã¦Streamlitã«è¡¨ç¤º
        if response.status_code == 200:
            response_data = response.json()
            assistant_message = response_data['choices'][0]['message']['content']
            if assistant_message:
                st.text_area("AI's response:", assistant_message, height=300)
        else:
            st.error("Failed to call OpenAI API")
    else:
        st.info('Please upload an image to get started.')
else:
    st.info('ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã€è³ªå•ã‚’å…¥åŠ›ã—ãŸã‚‰ã€Œè§£æã‚’é–‹å§‹ã€ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚')
    

